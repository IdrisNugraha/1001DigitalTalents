{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buat Corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['i saw her standing there',\n",
    "         'i saw the saw',\n",
    "         'but i give her an umbrella insted of the saw',\n",
    "         'i come but she run',\n",
    "         'she run and run away',\n",
    "         'i give her the umbrella but she give me the saw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melakukan tokenisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i saw her standing there i saw the saw but i give her an umbrella insted of the saw i come but she run she run and run away i give her the umbrella but she give me the saw \n"
     ]
    }
   ],
   "source": [
    "all_text_corpus = \"\"\n",
    "for line in corpus:\n",
    "    all_text_corpus += line + \" \"\n",
    "    \n",
    "print(all_text_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('i', 5), ('saw', 5), ('the', 4), ('her', 3), ('give', 3), ('but', 3), ('she', 3), ('run', 3), ('umbrella', 2), ('standing', 1), ('and', 1), ('of', 1), ('away', 1), ('there', 1), ('an', 1), ('me', 1), ('come', 1), ('insted', 1)]\n",
      "[(('the', 'saw'), 3), (('give', 'her'), 2), (('i', 'give'), 2), (('but', 'she'), 2), (('she', 'run'), 2), (('i', 'saw'), 2), (('of', 'the'), 1), (('give', 'me'), 1), (('her', 'standing'), 1), (('saw', 'but'), 1), (('saw', 'her'), 1), (('umbrella', 'insted'), 1), (('she', 'give'), 1), (('me', 'the'), 1), (('there', 'i'), 1), (('insted', 'of'), 1), (('standing', 'there'), 1), (('saw', 'i'), 1), (('i', 'come'), 1), (('saw', 'the'), 1), (('away', 'i'), 1), (('and', 'run'), 1), (('umbrella', 'but'), 1), (('come', 'but'), 1), (('run', 'she'), 1), (('her', 'the'), 1), (('her', 'an'), 1), (('but', 'i'), 1), (('run', 'and'), 1), (('run', 'away'), 1), (('the', 'umbrella'), 1), (('an', 'umbrella'), 1)]\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk import FreqDist\n",
    "freq_token = FreqDist(word_tokenize(all_text_corpus))\n",
    "\n",
    "print(freq_token.most_common())\n",
    "\n",
    "from nltk.util import ngrams\n",
    "\n",
    "freq_bigrams = FreqDist(ngrams(word_tokenize(all_text_corpus), 2))\n",
    "print(freq_bigrams.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('an', 'umbrella'): 1,\n",
       " ('and', 'run'): 1,\n",
       " ('away', 'i'): 1,\n",
       " ('but', 'i'): 1,\n",
       " ('but', 'she'): 2,\n",
       " ('come', 'but'): 1,\n",
       " ('give', 'her'): 2,\n",
       " ('give', 'me'): 1,\n",
       " ('her', 'an'): 1,\n",
       " ('her', 'standing'): 1,\n",
       " ('her', 'the'): 1,\n",
       " ('i', 'come'): 1,\n",
       " ('i', 'give'): 2,\n",
       " ('i', 'saw'): 2,\n",
       " ('insted', 'of'): 1,\n",
       " ('me', 'the'): 1,\n",
       " ('of', 'the'): 1,\n",
       " ('run', 'and'): 1,\n",
       " ('run', 'away'): 1,\n",
       " ('run', 'she'): 1,\n",
       " ('saw', 'but'): 1,\n",
       " ('saw', 'her'): 1,\n",
       " ('saw', 'i'): 1,\n",
       " ('saw', 'the'): 1,\n",
       " ('she', 'give'): 1,\n",
       " ('she', 'run'): 2,\n",
       " ('standing', 'there'): 1,\n",
       " ('the', 'saw'): 3,\n",
       " ('the', 'umbrella'): 1,\n",
       " ('there', 'i'): 1,\n",
       " ('umbrella', 'but'): 1,\n",
       " ('umbrella', 'insted'): 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(freq_bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcuting bigram probabilities:\n",
    "\n",
    "P( w<sub>i</sub> | w<sub>i-1</sub> ) = count ( w<sub>i-1</sub>, w<sub>i</sub> ) / count ( w<sub>i-1</sub> )\n",
    "\n",
    "In english..\n",
    "\n",
    "Probability that word<sub>i-1</sub> is followed by word<sub>i</sub> =\n",
    "[Num times we saw word<sub>i-1</sub> followed by word<sub>i</sub>] / [Num times we saw word<sub>i-1</sub>]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token:\n",
      "<FreqDist with 18 samples and 40 outcomes>\n",
      "\n",
      "bigrams:\n",
      "<FreqDist with 32 samples and 39 outcomes>\n",
      "\n",
      "text:\n",
      "i give the saw\n",
      "====================================\n",
      "('give', 'the')\n",
      "P(the | give) = P(('give', 'the')) / P(give)\n",
      "prob atas: 0\n",
      "prob bawah: 3\n",
      "P(the | give) = P(0) / P(3)\n",
      "0.03333333333333333518370504104\n",
      "------------------------------------\n",
      "('i', 'give')\n",
      "P(give | i) = P(('i', 'give')) / P(i)\n",
      "prob atas: 2\n",
      "prob bawah: 5\n",
      "P(give | i) = P(2) / P(5)\n",
      "0.4\n",
      "------------------------------------\n",
      "('the', 'saw')\n",
      "P(saw | the) = P(('the', 'saw')) / P(the)\n",
      "prob atas: 3\n",
      "prob bawah: 4\n",
      "P(saw | the) = P(3) / P(4)\n",
      "0.75\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import decimal\n",
    "\n",
    "def hitung_bigrams(token, bigrams, text):\n",
    "    print(\"token:\")\n",
    "    print(token)\n",
    "    print(\"\\nbigrams:\")\n",
    "    print(bigrams)\n",
    "    print(\"\\ntext:\")\n",
    "    print(text)\n",
    "    dict_bigrams = dict(bigrams)\n",
    "    dict_token = dict(token)\n",
    "    print('====================================')\n",
    "    \n",
    "    # explode text\n",
    "    token_text = word_tokenize(text)\n",
    "    bigrams_text = FreqDist(ngrams(token_text, 2))\n",
    "    \n",
    "    for i in bigrams_text:\n",
    "        print(i)\n",
    "        print(\"P({} | {}) = P({}) / P({})\".format(i[1], i[0], i, i[0]))\n",
    "        \n",
    "        try:\n",
    "            prob_a = dict_bigrams[i[0], i[1]]\n",
    "        except:\n",
    "            prob_a = 0\n",
    "            \n",
    "        try:\n",
    "            prob_b = dict_token[i[0]]\n",
    "        except:\n",
    "            prob_b = 0\n",
    "            \n",
    "        print(\"prob atas: \"+ str(prob_a))\n",
    "        print(\"prob bawah: \"+ str(prob_b))\n",
    "        print(\"P({} | {}) = P({}) / P({})\".format(i[1], i[0], prob_a, prob_b))\n",
    "        \n",
    "        #hitung prob\n",
    "        if prob_a <= 0 and prob_b > 0:\n",
    "            print(decimal.Decimal(prob_a+0.1)/decimal.Decimal(prob_b))\n",
    "        elif prob_a > 0 and prob_b <= 0:\n",
    "            print(decimal.Decimal(prob_a)/decimal.Decimal(prob_b+0.1))\n",
    "        elif prob_a <= 0 and prob_b <= 0:\n",
    "            print(decimal.Decimal(prob_a+0.1)/decimal.Decimal(prob_b+0.1))\n",
    "        elif prob_a > 0 and prob_b > 0:\n",
    "            print(decimal.Decimal(prob_a)/decimal.Decimal(prob_b))\n",
    "\n",
    "        print('------------------------------------')\n",
    "        \n",
    "hitung_bigrams(freq_token, freq_bigrams, \"i give the saw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating trigram probabilities:\n",
    "\n",
    "Building off the logic in bigram probabilities,\n",
    "\n",
    "P( w<sub>i</sub> | w<sub>i-1</sub> w<sub>i-2</sub> ) = count ( w<sub>i</sub>, w<sub>i-1</sub>, w<sub>i-2</sub> ) / count ( w<sub>i-1</sub>, w<sub>i-2</sub> )\n",
    "\n",
    "Example\n",
    "-------\n",
    "\n",
    "- P( Sam | I am ) \n",
    "= count( Sam I am ) / count(I am)\n",
    "= 1 / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "freq_token_bigrams = FreqDist(ngrams(word_tokenize(all_text_corpus), 2))\n",
    "\n",
    "# print(freq_token_bigrams.most_common())\n",
    "# print('__________')\n",
    "\n",
    "freq_token_trigrams = FreqDist(ngrams(word_tokenize(all_text_corpus), 3))\n",
    "# print(freq_token_trigrams.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token:\n",
      "<FreqDist with 32 samples and 39 outcomes>\n",
      "\n",
      "bigrams:\n",
      "<FreqDist with 37 samples and 38 outcomes>\n",
      "\n",
      "text:\n",
      "i saw the saw\n",
      "====================================\n",
      "('i', 'saw', 'the')\n",
      "P(i | saw the) = P(i saw the) / P(saw the)\n",
      "prob atas: 1\n",
      "prob bawah: 1\n",
      "P(saw | i) = P(1) / P(1)\n",
      "1\n",
      "------------------------------------\n",
      "('saw', 'the', 'saw')\n",
      "P(saw | the saw) = P(saw the saw) / P(the saw)\n",
      "prob atas: 1\n",
      "prob bawah: 3\n",
      "P(the | saw) = P(1) / P(3)\n",
      "0.3333333333333333333333333333\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import decimal\n",
    "\n",
    "def hitung_trigrams(token, bigrams, text):\n",
    "    print(\"token:\")\n",
    "    print(token)\n",
    "    print(\"\\nbigrams:\")\n",
    "    print(bigrams)\n",
    "    print(\"\\ntext:\")\n",
    "    print(text)\n",
    "    dict_bigrams = dict(bigrams)\n",
    "    dict_token = dict(token)\n",
    "    print('====================================')\n",
    "    \n",
    "    # explode text\n",
    "    token_text = word_tokenize(text)\n",
    "    trigrams_text = FreqDist(ngrams(token_text, 3))\n",
    "    \n",
    "    for i in trigrams_text:\n",
    "        print(i)\n",
    "        print(\"P({} | {} {}) = P({} {} {}) / P({} {})\".format(i[0], i[1], i[2], i[0], i[1], i[2], i[1], i[2]))\n",
    "        \n",
    "        try:\n",
    "            prob_a = dict_bigrams[i[0], i[1], i[2]]\n",
    "        except:\n",
    "            prob_a = 0\n",
    "            \n",
    "        try:\n",
    "            prob_b = dict_token[i[1], i[2]]\n",
    "        except:\n",
    "            prob_b = 0\n",
    "            \n",
    "        print(\"prob atas: \"+ str(prob_a))\n",
    "        print(\"prob bawah: \"+ str(prob_b))\n",
    "        print(\"P({} | {}) = P({}) / P({})\".format(i[1], i[0], prob_a, prob_b))\n",
    "        \n",
    "        #hitung prob\n",
    "        if prob_a <= 0 and prob_b > 0:\n",
    "            print(decimal.Decimal(prob_a+0.1)/decimal.Decimal(prob_b))\n",
    "        elif prob_a > 0 and prob_b <= 0:\n",
    "            print(decimal.Decimal(prob_a)/decimal.Decimal(prob_b+0.1))\n",
    "        elif prob_a <= 0 and prob_b <= 0:\n",
    "            print(decimal.Decimal(prob_a+0.1)/decimal.Decimal(prob_b+0.1))\n",
    "        elif prob_a > 0 and prob_b > 0:\n",
    "            print(decimal.Decimal(prob_a)/decimal.Decimal(prob_b))\n",
    "\n",
    "        print('------------------------------------')\n",
    "        \n",
    "hitung_trigrams(freq_token_bigrams, freq_token_trigrams, \"i saw the saw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
